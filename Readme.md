<h1>ToqiNet<h1>
<h2>Model Overview</h2>

<p>ToqiNet is an advanced deep learning model tailored for image classification tasks. It utilizes convolutional neural networks (CNNs) to extract features from input images and make accurate predictions about their respective classes. In this section, we'll explore how ToqiNet works and delve into its underlying algorithms and functionality.</p>

<h3>Functionality</h3>

<p>ToqiNet operates by processing input images through a series of convolutional and pooling layers to extract meaningful features. These features are then fed into fully connected layers for classification. Let's break down the key components of ToqiNet's functionality:</p>

<h4>Convolutional Layers</h4>

<p>The convolutional layers in ToqiNet serve as feature extractors, detecting patterns and shapes within the input images. Each convolutional layer applies a set of learnable filters to the input, producing feature maps that highlight relevant spatial information.</p>

<h4>Pooling Layers</h4>

<p>Pooling layers in ToqiNet reduce the spatial dimensions of the feature maps generated by the convolutional layers. This helps in capturing the most salient features while discarding redundant information, leading to more efficient processing and improved generalization.</p>

<h4>Fully Connected Layers</h4>

<p>The fully connected layers in ToqiNet take the flattened feature vectors from the preceding layers and perform classification based on learned representations. These layers enable ToqiNet to make predictions about the input images' classes with high accuracy.</p>

<h3>Algorithm</h3>

<p>Behind the scenes, ToqiNet employs sophisticated algorithms to optimize model performance and enhance training efficiency. Let's explore some of the key algorithms used in ToqiNet:</p>

<h4>Stochastic Gradient Descent (SGD)</h4>

<p>ToqiNet utilizes SGD as the optimization algorithm to iteratively update the model parameters based on the gradients computed from mini-batches of training data. SGD helps ToqiNet converge towards optimal parameter values and improves its ability to generalize to unseen data.</p>

<h4>Cross-Entropy Loss</h4>

<p>ToqiNet employs cross-entropy loss as the objective function to measure the discrepancy between the predicted class probabilities and the ground truth labels. By minimizing the cross-entropy loss during training, ToqiNet learns to make more accurate predictions and achieve higher classification accuracy.</p>

<h2>Training and Evaluation</h2>

<p>To train ToqiNet, we utilize labeled image datasets and follow a standard training procedure:</p>

<ol>
  <li>Prepare the training and validation datasets, ensuring proper data preprocessing and augmentation.</li>
  <li>Instantiate the ToqiNet model and define the optimizer and loss function.</li>
  <li>Iterate over the training dataset in mini-batches, computing predictions, calculating loss, and updating model parameters using backpropagation.</li>
  <li>Evaluate the trained model's performance on the validation dataset to assess its accuracy and generalization capability.</li>
</ol>

<h2>Usage</h2>
<h2>Code Snippets</h2>

<h3>Model Initialization and Setup</h3>

<p>Initialize the ToqiNet model, set up the device (GPU if available), and define other necessary configurations.</p>

<pre><code>import torch
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.transforms import transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
from src.ToqiNet import ToqiNet, ToqiDataset


"""
In here we are transforming the image for its comapatibility befor testing.

"""
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

test_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

"""
There we are defining the training directory and lso the testing through directory for checking the accurecy.
ToqiDataset is optimazie for handeling the dataset and preprocess the data before sending it for training

"""
train_dataset = ToqiDataset(root_dir='your training dataset path', transform=train_transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

test_dataset = ToqiDataset(root_dir='your training dataset path', transform=test_transform)
test_loader = DataLoader(test_dataset, batch_size=32)

"""
in here the dataset for training path must be given into the model 

"""
model = ToqiNet(num_classes=train_dataset.num_classes)
model.set_dataset_root('your training dataset path')
model.to(model.device)
</code></pre>

<h3>Training the Model</h3>

<p>Train the ToqiNet model using the defined data loaders, optimizer, and loss function.</p>

<pre><code># Define optimizer and loss function
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(model.device)

"""
for test purpose i have taken a small size of epochs it can be customaizeable

"""
num_epochs = 25
print_every = 5  

"""
Looping through  all the inputed and preprocess value

"""
def evaluate_model(model, test_loader, criterion):
    model.eval()
    correct = 0
    total = 0
    test_loss = 0.0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = correct / total
    avg_test_loss = test_loss / len(test_loader)
    print(f'Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')



# Training loop
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    pbar = tqdm(enumerate(train_loader), total=len(train_loader))
    for i, (inputs, labels) in pbar:
        inputs, labels = inputs.to(model.device), labels.to(model.device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        pbar.set_description(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / (i + 1):.4f}")

    if (epoch + 1) % print_every == 0:
        print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}")

# Evaluate the model on the test dataset
evaluate_model(model, test_loader, criterion)

</code></pre>

<h3>Saving the Model</h3>

<p>Save the trained model and class labels to files for future use.</p>

<pre><code># Save the trained model
"""
in here i have tried to save the model and save the class along with it through "class_to_idx". this can be done by creating a separate .txt file to store the class


"""
torch.save({
    'model_state_dict': model.state_dict(),  # Save model parameters
    'class_to_idx': train_dataset.class_to_idx,  # Save class to index mapping
    'similarity_threshold': model.similarity_threshold  # Save similarity threshold
}, 'your output directory to save the file and also the file name ')

</code></pre>

<h3>Evaluating Model Performance</h3>

<p>Evaluate the performance of the trained model on the test dataset.</p>

<pre><code># Evaluate model performance
model.eval()
correct = 0
total = 0

class_correct = defaultdict(int)
class_total = defaultdict(int)

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        for pred, label in zip(predicted.cpu().numpy(), labels.cpu().numpy()):
            class_correct[pred] += int(pred == label)
            class_total[label] += 1

accuracy = 100 * correct / total
print('Accuracy of the network on the test images: %.2f %%' % accuracy)

for class_name, class_idx in test_dataset.data.class_to_idx.items():
    print(f'Class: {class_name}, Total Images: {class_total[class_idx]}')
</code></pre>
<h3>Model Training</h3>

<p>Training ToqiNet is a meticulously orchestrated process that leverages advanced optimization techniques and rigorous validation protocols. Powered by sophisticated algorithms and cutting-edge hardware, ToqiNet undergoes extensive training to ensure superior performance and robustness. Rigorous testing and validation procedures validate ToqiNet's proficiency and reliability across diverse datasets and scenarios.</p>

<h2>Test Results</h2>

<h3>Tested Hardware Configuration</h3>

<ul>
  <li>Processor: Intel Core i7 11th Gen.</li>
  <li>Graphics Card: NVIDIA Tesla P100</li>
  <li>Memory: 16GB RAM</li>
</ul>

<h3>Test Results Summary</h3>

<table>
  <thead>
    <tr>
      <th>Model Name</th>
      <th>Test Images (both classes)</th>
      <th>Accuracy</th>
      <th>Parameters</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ToqiNet</td>
      <td>8000</td>
      <td>92.65%</td>
      <td>71M</td>
    </tr>
  </tbody>
</table>

<h2>Data Loss and Validation Graphs</h2>

<h3>Data Loss Graph</h3>

<p>The data loss graph illustrates the convergence of the training process over successive epochs. A decreasing trend in data loss indicates that ToqiNet is effectively learning from the training data and improving its predictive capabilities.</p>

<h3>Validation Accuracy Graph</h3>

<p>The validation accuracy graph provides insights into ToqiNet's generalization performance on unseen data. By monitoring the validation accuracy throughout the training process, we can evaluate ToqiNet's ability to generalize to new images and detect potential overfitting or underfitting issues.</p>

<h2>Usage</h2>

<p>For usage instructions and installation details, please refer to the <a href="docs/README.md">documentation</a>.</p>

<h2>Contributions</h2>

<p>Contributions to ToqiNet are welcome and encouraged. As an open-source project, ToqiNet thrives on collaboration and community involvement. If you encounter any issues or have suggestions for enhancements, please don't hesitate to open an issue or submit a pull request.</p>

<h2>License and Copyright</h2>

<p>© 2024 ToqiNet Contributors</p>

<p>This project is licensed under the MIT License. It is usable for any development and encourages open-source contributions.</p>

<p>For inquiries, please contact tahmeedtoqi123@gmail.com.</p>

<p><a href="https://web.facebook.com/tahmeedtoqi777/">account</a>.</p>
